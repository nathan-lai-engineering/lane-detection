{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I69gTInwkEBs",
    "outputId": "5dffd3bf-baf2-43f3-9d91-012754d22b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\Desktop\\Test Detection\\lane-detection\\YOLOP\n"
     ]
    }
   ],
   "source": [
    "%cd ./YOLOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qr-KBth7EaR5"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UtX7Yzq9EZqg"
   },
   "outputs": [],
   "source": [
    "################################\n",
    "# Directories\n",
    "################################\n",
    "\n",
    "# directory where videos are being performed detections on\n",
    "source_dir = \"../videos\"\n",
    "\n",
    "# folder for where images are saved if detection performed on images\n",
    "save_dir = \"../save\"\n",
    "\n",
    "# folder where raw output from detections are saved as csv\n",
    "csv_dir = \"../csv_raw_output\"\n",
    "\n",
    "# folder where post processed csvs are being saved\n",
    "processed_csv_dir = \"../processed\"\n",
    "\n",
    "# folder where external bounding boxes are being used\n",
    "external_bounding_boxes = \"../external_bounding_boxes\"\n",
    "\n",
    "# folder where pandas friendly csv are being saved\n",
    "zeros_dir = \"../lane_zeros\"\n",
    "\n",
    "# folder for storing only the closest bounding boxes (-1 0 1)\n",
    "closest_dir = \"../closest_boxes\"\n",
    "\n",
    "\n",
    "################################\n",
    "# Settings for DETECTION ONLY\n",
    "################################\n",
    "\n",
    "# set a center so it doesn't need to check for a new center\n",
    "# there's a cell at the bottom that can help find the center\n",
    "preset_center = 615\n",
    "\n",
    "# fps for detection to run at\n",
    "detection_fps = 30\n",
    "\n",
    "# minimum acceptable confidence \n",
    "confidence_threshold = 0.5\n",
    "\n",
    "# Will not perform detection unless there are external bounding boxes for that video\n",
    "enforce_external_boxes = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbvvemnRucYF"
   },
   "source": [
    "list of dictionaries with keys [\"frame\", \"rois\", \"class_ids\", \"scores\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwPy3ylhfWA7"
   },
   "source": [
    "##Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kGOAEpjZfYGj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import statistics as stats\n",
    "import cv2\n",
    "\n",
    "def read_csv_detection(detection):\n",
    "  detection_data = detection.split(\" \")\n",
    "  if detection_data[0] == \"None\":\n",
    "    lane_number = None\n",
    "  else:\n",
    "    lane_number = int(detection_data[0])\n",
    "  x1 = int(float(detection_data[1]))\n",
    "  y1 = int(float(detection_data[2]))\n",
    "  x2 = int(float(detection_data[3]))\n",
    "  y2 = int(float(detection_data[4]))\n",
    "  conf = float(detection_data[5])\n",
    "  frame_center = int(float(detection_data[6]))\n",
    "  if len(detection_data) >= 8:\n",
    "    vehicle_class = int(float(detection_data[7]))\n",
    "    return lane_number, x1, y1, x2, y2, conf, frame_center, vehicle_class\n",
    "  return lane_number, x1, y1, x2, y2, conf, frame_center\n",
    "\n",
    "def find_lane_zero(detections):\n",
    "  for detection in detections:\n",
    "    data = read_csv_detection(detection)\n",
    "    if data[0] == 0:\n",
    "      return data\n",
    "  return None\n",
    "\n",
    "#box = [x1,y1,x2,y2]\n",
    "#returns mean and standard deviations list of each coordinate\n",
    "def get_boxes_stats(boxes):\n",
    "  stdev = None\n",
    "  mean = None\n",
    "  if len(boxes) > 0:\n",
    "    x1_list = [x1[0] for x1 in boxes]\n",
    "    y1_list = [y1[1] for y1 in boxes]\n",
    "    x2_list = [x2[2] for x2 in boxes]\n",
    "    y2_list = [y2[3] for y2 in boxes]\n",
    "    mean = [int(stats.mean(x1_list)), int(stats.mean(y1_list)), int(stats.mean(x2_list)), int(stats.mean(y2_list))]\n",
    "    stdev = [stats.pstdev(x1_list), stats.pstdev(y1_list), stats.pstdev(x2_list), stats.pstdev(y2_list)]\n",
    "  return mean, stats.mean(stdev)\n",
    "\n",
    "def find_largest_box(detections, target_lane_number):\n",
    "  largest_detection = None\n",
    "  for detection in detections:\n",
    "    lane_number, x1, y1, x2, y2 = read_csv_detection(detection)[:5]\n",
    "    if(target_lane_number == lane_number):\n",
    "      if(largest_detection is None):\n",
    "        largest_detection = detection\n",
    "      else:\n",
    "        _ , l_x1, l_y1, l_x2, l_y2 = read_csv_detection(largest_detection)[:5]\n",
    "        largest_area = (l_x2 - l_x1) * (l_y2 - l_y1)\n",
    "        area = (x2-x1) * (y2-y1)\n",
    "        if area > largest_area:\n",
    "          largest_detection = detection\n",
    "  return largest_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTGwfo7LFSZU"
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0veGTpoNkY3G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "cmd_source_dir = \"\\\"\" + source_dir + \"\\\"\"\n",
    "cmd_save_dir = \"\\\"\" + save_dir + \"\\\"\"\n",
    "cmd_csv_dir = \"\\\"\" + csv_dir + \"\\\"\"\n",
    "\n",
    "cmd_external_boxes = None\n",
    "if external_bounding_boxes:\n",
    "  cmd_external_boxes = \"\\\"\" + external_bounding_boxes + \"\\\"\"\n",
    "\n",
    "if preset_center:\n",
    "  !python tools/demo.py --source {cmd_source_dir} --save-dir {cmd_save_dir}  --detect-fps {detection_fps} --save-csv {cmd_csv_dir} --external-boxes {cmd_external_boxes} --img-center {preset_center} --enforce-external {enforce_external_boxes}\n",
    "else:\n",
    "  !python tools/demo.py --source {cmd_source_dir} --save-dir {cmd_save_dir}  --detect-fps {detection_fps} --save-csv {cmd_csv_dir} --external-boxes {cmd_external_boxes} --enforce-external {enforce_external_boxes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pz7eny7ZGck"
   },
   "source": [
    "## Post-Processing\n",
    "detection format: [lane number, x1, y1, x2, y2, confidence, lane center]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VGrZl9NZZIVa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using source video\n",
      "20200306_123926_EF.mp4\n",
      "outlier 5 5.172355213109037 5.62062719799557 due to complete lack of good data\n",
      "outlier 6 5.172355213109037 5.6109302692547605 due to complete lack of good data\n",
      "outlier 7 5.172355213109037 5.743853709874486 due to complete lack of good data\n",
      "outlier 8 5.172355213109037 5.832420415576075 due to complete lack of good data\n",
      "outlier 12 5.229974135373411 6.029472059684352 due to complete lack of good data\n",
      "outlier 13 5.229974135373411 6.133081536226731 due to complete lack of good data\n",
      "outlier 14 5.229974135373411 6.056943178539585 due to complete lack of good data\n",
      "outlier 15 5.229974135373411 5.879508237420512 due to complete lack of good data\n",
      "outlier 16 5.229974135373411 5.76430644409956 due to complete lack of good data\n",
      "outlier 17 5.375 5.53476656992194 due to complete lack of good data\n",
      "outlier 18 0.0 5.033357867014768 due to complete lack of good data\n",
      "outlier 40 5.161554445513393 5.456156794350426 due to complete lack of good data\n",
      "outlier 41 5.382497751386339 5.456156794350426 due to complete lack of good data\n",
      "outlier 47 5.278652061572772 5.329892969683201 due to complete lack of good data\n",
      "outlier 48 5.278652061572772 5.386694223906059 due to complete lack of good data\n",
      "outlier 49 5.278652061572772 5.459997571778591 due to complete lack of good data\n",
      "outlier 50 5.2827956959925295 5.377085504620488 due to complete lack of good data\n",
      "outlier 52 5.12229349837418 5.477529133881248 due to complete lack of good data\n",
      "outlier 53 0.25 5.701977096611083 due to complete lack of good data\n",
      "outlier 54 0.0 5.67078686842673 due to complete lack of good data\n",
      "outlier 55 0.0 5.273972613582957 due to complete lack of good data\n",
      "outlier 61 5.805198870536188 5.886017667986472 due to complete lack of good data\n",
      "outlier 62 5.805198870536188 6.378095804486261 due to complete lack of good data\n",
      "outlier 63 5.805198870536188 6.378831553749298 due to complete lack of good data\n",
      "outlier 64 5.28919784941919 5.8192513882462675 due to complete lack of good data\n",
      "outlier 65 5.717583095306143 5.758975468167432 due to complete lack of good data\n",
      "outlier 66 6.125 6.086777626469129 due to complete lack of good data\n",
      "outlier 67 0.0 6.703568581049747 due to complete lack of good data\n",
      "outlier 68 None 6.765118353520108 due to complete lack of good data\n",
      "outlier 69 None 6.842180556271956 due to complete lack of good data\n",
      "outlier 70 None 6.887896503391088 due to complete lack of good data\n",
      "outlier 71 None 6.925948337694438 due to complete lack of good data\n",
      "outlier 72 None 6.543065219841821 due to complete lack of good data\n",
      "outlier 73 None 5.237454958808003 due to complete lack of good data\n",
      "outlier 159 5.175898823160684 7.074409256384435 due to complete lack of good data\n",
      "outlier 160 5.535056771531226 6.892067180130292 due to complete lack of good data\n",
      "outlier 161 5.96156473687348 6.884229733110478 due to complete lack of good data\n",
      "outlier 162 6.460909792683646 6.749574020747952 due to complete lack of good data\n",
      "outlier 163 7.0710678118654755 5.560275199134958 due to complete lack of good data\n",
      "outlier 191 5.917821430888956 5.7921125384087455 due to complete lack of good data\n",
      "outlier 192 6.295488305274467 6.337532260082649 due to complete lack of good data\n",
      "outlier 193 6.7727667509729175 6.470236286813335 due to complete lack of good data\n",
      "outlier 194 7.324777582033823 5.501061938651929 due to complete lack of good data\n",
      "outlier 197 6.9500955007309155 5.671238751929288 due to complete lack of good data\n",
      "outlier 198 6.375 7.058646319800068 due to complete lack of good data\n",
      "outlier 199 6.375 7.100978113420209 due to complete lack of good data\n",
      "outlier 200 6.375 6.848799585648068 due to complete lack of good data\n",
      "outlier 201 6.375 6.698428481094751 due to complete lack of good data\n",
      "outlier 202 6.375 7.40256649640056 due to complete lack of good data\n",
      "outlier 203 0.0 7.159846276421429 due to complete lack of good data\n",
      "outlier 204 None 7.332244211764736 due to complete lack of good data\n",
      "outlier 205 None 7.362362452259714 due to complete lack of good data\n",
      "outlier 206 None 6.2664796027813905 due to complete lack of good data\n",
      "outlier 207 None 5.722669941591188 due to complete lack of good data\n",
      "outlier 208 None 6.375005659072146 due to complete lack of good data\n",
      "outlier 209 None 6.309653957309054 due to complete lack of good data\n",
      "outlier 210 None 6.317312912094185 due to complete lack of good data\n",
      "outlier 211 None 6.18244841784025 due to complete lack of good data\n",
      "outlier 212 None 6.18244841784025 due to complete lack of good data\n",
      "outlier 213 None 6.339236457376782 due to complete lack of good data\n",
      "outlier 214 None 5.608085051198308 due to complete lack of good data\n",
      "outlier 242 6.715588692534338 6.399533446833756 due to complete lack of good data\n",
      "outlier 243 6.5240043261045235 6.351737983491307 due to complete lack of good data\n",
      "outlier 244 5.843740333407109 6.374893988833349 due to complete lack of good data\n",
      "outlier 249 5.99207016715734 8.061991047777994 due to complete lack of good data\n",
      "outlier 250 5.99207016715734 8.00533089943685 due to complete lack of good data\n",
      "outlier 251 5.99207016715734 7.568379590775646 due to complete lack of good data\n",
      "outlier 252 5.99207016715734 7.755221689219607 due to complete lack of good data\n",
      "outlier 253 6.542617691047568 7.967900772859322 due to complete lack of good data\n",
      "outlier 254 6.875 8.029769623757467 due to complete lack of good data\n",
      "outlier 255 0.0 8.077283678862907 due to complete lack of good data\n",
      "outlier 256 None 7.929797238025582 due to complete lack of good data\n",
      "outlier 257 None 7.894203508108772 due to complete lack of good data\n",
      "outlier 258 None 7.266537028925928 due to complete lack of good data\n",
      "outlier 259 None 7.232275906341833 due to complete lack of good data\n",
      "outlier 260 None 7.980307404133817 due to complete lack of good data\n",
      "outlier 261 None 7.744180889280544 due to complete lack of good data\n",
      "outlier 262 None 7.147140591465716 due to complete lack of good data\n",
      "outlier 263 None 5.633331756012183 due to complete lack of good data\n",
      "outlier 264 None 7.144062168683902 due to complete lack of good data\n",
      "outlier 265 None 7.80953845066223 due to complete lack of good data\n",
      "outlier 266 None 7.747211477062108 due to complete lack of good data\n",
      "outlier 267 None 7.860467762033285 due to complete lack of good data\n",
      "outlier 268 None 7.863782572415574 due to complete lack of good data\n",
      "outlier 269 None 7.893729727410885 due to complete lack of good data\n",
      "outlier 270 None 7.956689303526945 due to complete lack of good data\n",
      "outlier 271 None 7.343479729495514 due to complete lack of good data\n",
      "outlier 272 None 5.676439338637697 due to complete lack of good data\n",
      "outlier 318 5.491418655249345 5.668153432750697 due to complete lack of good data\n",
      "outlier 319 5.758696207379091 7.2033344752219985 due to complete lack of good data\n",
      "outlier 320 6.187649506156374 7.765352529505064 due to complete lack of good data\n",
      "outlier 321 6.710405891687403 7.511367770271375 due to complete lack of good data\n",
      "outlier 322 7.331134520179252 7.712576890093412 due to complete lack of good data\n",
      "outlier 323 8.0 7.90482945250966 due to complete lack of good data\n",
      "outlier 324 0.0 8.13650888710661 due to complete lack of good data\n",
      "outlier 325 None 8.125692625332697 due to complete lack of good data\n",
      "outlier 326 None 7.43461214317383 due to complete lack of good data\n",
      "outlier 327 None 7.404451730250046 due to complete lack of good data\n",
      "outlier 328 None 5.939172735772172 due to complete lack of good data\n",
      "outlier 329 None 6.013893894203924 due to complete lack of good data\n",
      "outlier 330 None 6.14466727138923 due to complete lack of good data\n",
      "outlier 331 None 6.162680727756289 due to complete lack of good data\n",
      "outlier 332 None 6.166324581857554 due to complete lack of good data\n",
      "outlier 333 None 6.1896999754532 due to complete lack of good data\n",
      "outlier 365 7.760832391495781 6.532132001965271 due to complete lack of good data\n",
      "outlier 366 8.139434493427007 6.513203852208092 due to complete lack of good data\n",
      "outlier 367 8.469320868852993 6.442681749332907 due to complete lack of good data\n",
      "outlier 368 8.663221581892238 6.407693978596496 due to complete lack of good data\n",
      "outlier 369 8.309953376308886 8.353817286999437 due to complete lack of good data\n",
      "outlier 370 8.875 8.346529763055813 due to complete lack of good data\n",
      "outlier 371 0.0 9.080312526698311 due to complete lack of good data\n",
      "outlier 372 None 9.115000960575712 due to complete lack of good data\n",
      "outlier 373 None 9.077202816624917 due to complete lack of good data\n",
      "outlier 374 None 9.04383389672443 due to complete lack of good data\n",
      "outlier 375 None 9.131177458266803 due to complete lack of good data\n",
      "outlier 376 None 9.168426788295129 due to complete lack of good data\n",
      "outlier 377 None 9.299585279934377 due to complete lack of good data\n",
      "outlier 378 None 8.579080082600097 due to complete lack of good data\n",
      "outlier 379 None 6.674092542706392 due to complete lack of good data\n",
      "outlier 380 None 6.692896718895024 due to complete lack of good data\n",
      "outlier 383 9.25 6.672375717178259 due to complete lack of good data\n",
      "outlier 384 9.25 8.352442301310257 due to complete lack of good data\n",
      "outlier 385 9.25 9.090232558255185 due to complete lack of good data\n",
      "outlier 386 9.25 9.100285801286015 due to complete lack of good data\n",
      "outlier 387 9.25 8.430680056608214 due to complete lack of good data\n",
      "outlier 388 9.25 6.61022895905392 due to complete lack of good data\n",
      "outlier 389 0.0 6.617598495773525 due to complete lack of good data\n",
      "outlier 390 None 8.468394510756905 due to complete lack of good data\n",
      "outlier 391 None 9.334241875538165 due to complete lack of good data\n",
      "outlier 392 None 9.413605053866407 due to complete lack of good data\n",
      "outlier 393 None 8.697673692818107 due to complete lack of good data\n",
      "outlier 394 None 6.661152534983473 due to complete lack of good data\n",
      "outlier 397 9.375 6.308363318294306 due to complete lack of good data\n",
      "outlier 398 9.375 6.388516074185869 due to complete lack of good data\n",
      "outlier 399 9.375 6.369859292946259 due to complete lack of good data\n",
      "outlier 400 9.375 6.387869154890751 due to complete lack of good data\n",
      "outlier 401 9.375 6.389584645913317 due to complete lack of good data\n",
      "outlier 402 9.375 8.176121796650873 due to complete lack of good data\n",
      "outlier 403 0.0 9.013798854540537 due to complete lack of good data\n",
      "outlier 404 None 8.142486543407692 due to complete lack of good data\n",
      "outlier 405 None 7.792719539168432 due to complete lack of good data\n",
      "outlier 406 None 8.05331801736661 due to complete lack of good data\n",
      "outlier 407 None 7.281312613382266 due to complete lack of good data\n",
      "outlier 408 None 5.3263525157922995 due to complete lack of good data\n",
      "outlier 409 None 5.332670755273814 due to complete lack of good data\n",
      "outlier 410 None 5.337139603166034 due to complete lack of good data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomoly detected 459 None [628, 448, 645, 462]\n",
      "anomoly detected 460 None [628, 448, 645, 462]\n",
      "anomoly detected 463 None [627, 448, 645, 462]\n",
      "anomoly detected 464 None [627, 448, 645, 462]\n",
      "anomoly detected 473 None [626, 446, 644, 461]\n",
      "outlier 512 7.172507461619134 7.4006802115199255 due to complete lack of good data\n",
      "outlier 513 7.644216800789881 9.588315897723707 due to complete lack of good data\n",
      "outlier 514 8.16167368140847 9.588315897723707 due to complete lack of good data\n",
      "outlier 515 8.83456490391585 10.70317454781796 due to complete lack of good data\n",
      "outlier 516 9.614598750094682 10.679298019725726 due to complete lack of good data\n",
      "outlier 517 10.125 10.63098108952136 due to complete lack of good data\n",
      "outlier 518 0.0 9.839648393846112 due to complete lack of good data\n",
      "outlier 519 None 9.765188967572424 due to complete lack of good data\n",
      "outlier 520 None 7.710338447998057 due to complete lack of good data\n",
      "outlier 521 None 7.688850750697299 due to complete lack of good data\n",
      "outlier 821 19.934024844539405 28.872271375965482 due to complete lack of good data\n",
      "outlier 822 21.10440906946213 28.841988984801976 due to complete lack of good data\n",
      "outlier 823 22.64179650511915 28.95324657694766 due to complete lack of good data\n",
      "outlier 824 24.58777286435665 28.912514646373985 due to complete lack of good data\n",
      "outlier 825 26.880191780600047 26.526653311693646 due to complete lack of good data\n",
      "outlier 826 29.0 29.32202479202827 due to complete lack of good data\n",
      "outlier 827 0.0 29.507044280363825 due to complete lack of good data\n",
      "outlier 828 None 27.118378321068736 due to complete lack of good data\n",
      "outlier 829 None 27.128683418148906 due to complete lack of good data\n",
      "outlier 830 None 21.14148071167072 due to complete lack of good data\n",
      "outlier 831 None 21.140047247417503 due to complete lack of good data\n",
      "outlier 833 0.0 22.145590849644982 due to complete lack of good data\n",
      "outlier 834 0.0 22.101484528631197 due to complete lack of good data\n",
      "outlier 835 0.0 22.018760185146732 due to complete lack of good data\n",
      "outlier 836 0.0 22.027135826334494 due to complete lack of good data\n",
      "outlier 837 0.0 28.934421452461912 due to complete lack of good data\n",
      "outlier 838 0.0 31.85373484754626 due to complete lack of good data\n",
      "outlier 839 0.0 31.93145068949506 due to complete lack of good data\n",
      "outlier 840 None 32.20953509253265 due to complete lack of good data\n",
      "outlier 841 None 29.416471160006182 due to complete lack of good data\n",
      "outlier 842 None 23.25050381739448 due to complete lack of good data\n",
      "outlier 866 25.48971802804157 37.22651137833841 due to complete lack of good data\n",
      "outlier 867 27.255995015247965 37.353834756038694 due to complete lack of good data\n",
      "outlier 868 29.38392920264447 37.413099778948094 due to complete lack of good data\n",
      "outlier 869 31.939735261050735 34.252265055787184 due to complete lack of good data\n",
      "outlier 870 34.944385290723595 26.691452174791213 due to complete lack of good data\n",
      "outlier 871 37.25 34.453502449848045 due to complete lack of good data\n",
      "outlier 872 0.0 37.728640387957086 due to complete lack of good data\n",
      "outlier 873 None 37.730176735137455 due to complete lack of good data\n",
      "outlier 874 None 34.536851520115306 due to complete lack of good data\n",
      "outlier 875 None 34.531479140630836 due to complete lack of good data\n",
      "outlier 876 None 34.575563887228604 due to complete lack of good data\n",
      "outlier 877 None 34.64179512898463 due to complete lack of good data\n",
      "outlier 878 None 35.117047315327795 due to complete lack of good data\n",
      "outlier 879 None 35.5856331363069 due to complete lack of good data\n",
      "outlier 880 None 39.106767801285876 due to complete lack of good data\n",
      "outlier 881 None 39.07915034299871 due to complete lack of good data\n",
      "outlier 882 None 35.69529752067347 due to complete lack of good data\n",
      "outlier 883 None 27.824269743166123 due to complete lack of good data\n",
      "outlier 884 None 0.7570820770145643 due to future boxes lacking data\n",
      "outlier 885 None 27.867302057188873 due to complete lack of good data\n",
      "outlier 886 None 36.047013283388374 due to complete lack of good data\n",
      "outlier 887 None 39.51305760836841 due to complete lack of good data\n",
      "outlier 888 None 39.60968993927165 due to complete lack of good data\n",
      "outlier 889 None 39.68261674297141 due to complete lack of good data\n",
      "outlier 890 None 36.28795200324502 due to complete lack of good data\n",
      "outlier 891 None 36.52148266026683 due to complete lack of good data\n",
      "outlier 892 None 36.67125215018336 due to complete lack of good data\n",
      "outlier 893 None 36.87923596572303 due to complete lack of good data\n",
      "outlier 894 None 36.85616710477224 due to complete lack of good data\n",
      "outlier 895 None 28.69257260632688 due to complete lack of good data\n",
      "outlier 896 None 28.730890123519615 due to complete lack of good data\n",
      "outlier 897 None 28.768400726472624 due to complete lack of good data\n",
      "outlier 898 None 29.330895457247617 due to complete lack of good data\n",
      "outlier 899 None 37.691857563069064 due to complete lack of good data\n",
      "outlier 900 None 37.59884371283384 due to complete lack of good data\n",
      "outlier 901 None 41.06264359482265 due to complete lack of good data\n",
      "outlier 902 None 41.18898288033017 due to complete lack of good data\n",
      "outlier 903 None 41.57709542873843 due to complete lack of good data\n",
      "outlier 904 None 41.872260092999 due to complete lack of good data\n",
      "outlier 905 None 38.31444246305581 due to complete lack of good data\n",
      "outlier 906 None 38.02296982657921 due to complete lack of good data\n",
      "outlier 907 None 41.56210043955708 due to complete lack of good data\n",
      "outlier 908 None 41.277929137160086 due to complete lack of good data\n",
      "outlier 909 None 41.19166088907275 due to complete lack of good data\n",
      "outlier 910 None 37.78626938234571 due to complete lack of good data\n",
      "outlier 911 None 29.372186458072385 due to complete lack of good data\n",
      "outlier 912 None 0.5952704865739672 due to future boxes lacking data\n",
      "outlier 914 0.0 29.251168558469992 due to complete lack of good data\n",
      "outlier 915 0.0 37.73425309506483 due to complete lack of good data\n",
      "outlier 916 0.0 38.01784661621247 due to complete lack of good data\n",
      "outlier 917 0.0 38.15818011380311 due to complete lack of good data\n",
      "outlier 918 0.0 38.21393551507876 due to complete lack of good data\n",
      "outlier 919 0.0 38.254040439201255 due to complete lack of good data\n",
      "outlier 920 0.0 38.13922007791502 due to complete lack of good data\n",
      "outlier 921 None 29.5455658497197 due to complete lack of good data\n",
      "outlier 922 None 29.85107954856253 due to complete lack of good data\n",
      "outlier 923 None 38.439001454770185 due to complete lack of good data\n",
      "outlier 924 None 38.427785806709615 due to complete lack of good data\n",
      "outlier 925 None 42.15003315808497 due to complete lack of good data\n",
      "outlier 926 None 41.94783251452875 due to complete lack of good data\n",
      "outlier 927 None 41.89107410800802 due to complete lack of good data\n",
      "outlier 928 None 42.02991905855952 due to complete lack of good data\n",
      "outlier 929 None 42.13720352437392 due to complete lack of good data\n",
      "outlier 930 None 38.587582844885695 due to complete lack of good data\n",
      "outlier 931 None 38.67820087174258 due to complete lack of good data\n",
      "outlier 932 None 30.11862138654578 due to complete lack of good data\n",
      "outlier 933 None 30.156099822706054 due to complete lack of good data\n",
      "outlier 934 None 38.73315644461283 due to complete lack of good data\n",
      "outlier 935 None 29.84522544964775 due to complete lack of good data\n",
      "outlier 936 None 38.72075777980365 due to complete lack of good data\n",
      "outlier 937 None 42.48120090681686 due to complete lack of good data\n",
      "outlier 938 None 42.53510131215409 due to complete lack of good data\n",
      "outlier 939 None 42.6619756558949 due to complete lack of good data\n",
      "outlier 940 None 42.69769111146954 due to complete lack of good data\n",
      "outlier 941 None 42.85977480091241 due to complete lack of good data\n",
      "outlier 942 None 42.90087706825002 due to complete lack of good data\n",
      "outlier 943 None 42.91094514521703 due to complete lack of good data\n",
      "outlier 944 None 42.92037815519494 due to complete lack of good data\n",
      "outlier 945 None 42.879139830554884 due to complete lack of good data\n",
      "outlier 946 None 42.89007247629413 due to complete lack of good data\n",
      "outlier 947 None 39.07383111531086 due to complete lack of good data\n",
      "outlier 948 None 42.83468552115991 due to complete lack of good data\n",
      "outlier 949 None 42.87941349666978 due to complete lack of good data\n",
      "outlier 950 None 42.89178476072433 due to complete lack of good data\n",
      "outlier 951 None 39.173858506805026 due to complete lack of good data\n",
      "outlier 952 None 39.2681659059282 due to complete lack of good data\n",
      "outlier 953 None 30.318316090169503 due to complete lack of good data\n",
      "outlier 954 None 0.6515156149204312 due to future boxes lacking data\n",
      "outlier 975 0.7884122625478865 39.89514945896756 due to past boxes lacking data\n",
      "outlier 976 0.6468551050686695 40.13347134324515 due to past boxes lacking data\n",
      "outlier 977 0.5320318436170149 43.78278291148722 due to past boxes lacking data\n",
      "outlier 979 0.914439393320952 43.46408777334008 due to past boxes lacking data\n",
      "outlier 981 0.9510177134610197 39.358616804986106 due to past boxes lacking data\n",
      "outlier 982 0.375 30.35761700004916 due to complete lack of good data\n",
      "outlier 983 0.375 0.876803813301219 due to future boxes lacking data\n",
      "outlier 984 0.375 30.789669949771383 due to complete lack of good data\n",
      "outlier 985 0.375 30.608040298240326 due to complete lack of good data\n",
      "outlier 986 0.0 30.42327017315641 due to complete lack of good data\n",
      "outlier 987 0.0 39.37162139046877 due to complete lack of good data\n",
      "outlier 988 None 39.12759141532054 due to complete lack of good data\n",
      "outlier 989 None 42.88183995032862 due to complete lack of good data\n",
      "outlier 990 None 42.84637239177101 due to complete lack of good data\n",
      "outlier 991 None 43.299419470860194 due to complete lack of good data\n",
      "outlier 992 None 39.541292895883764 due to complete lack of good data\n",
      "outlier 993 None 30.714534776317063 due to complete lack of good data\n",
      "outlier 994 None 30.791944930569002 due to complete lack of good data\n",
      "outlier 995 None 29.953432786094865 due to complete lack of good data\n",
      "outlier 996 None 38.44663786205078 due to complete lack of good data\n",
      "outlier 997 None 41.97063175489299 due to complete lack of good data\n",
      "outlier 998 None 41.724547829733496 due to complete lack of good data\n",
      "outlier 999 None 42.24366954841699 due to complete lack of good data\n",
      "outlier 1000 None 42.50306021370873 due to complete lack of good data\n",
      "outlier 1001 None 42.821955670386885 due to complete lack of good data\n",
      "outlier 1002 None 42.752102080320654 due to complete lack of good data\n",
      "outlier 1003 None 39.227968131303584 due to complete lack of good data\n",
      "outlier 1004 None 38.44137312330964 due to complete lack of good data\n",
      "outlier 1005 None 29.745348044759638 due to complete lack of good data\n",
      "outlier 1006 None 37.99374941660263 due to complete lack of good data\n",
      "outlier 1007 None 38.23197256218943 due to complete lack of good data\n",
      "outlier 1008 None 41.57929746724449 due to complete lack of good data\n",
      "outlier 1009 None 41.44234543430013 due to complete lack of good data\n",
      "outlier 1010 None 37.750614665852865 due to complete lack of good data\n",
      "outlier 1011 None 37.4143871102137 due to complete lack of good data\n",
      "outlier 1012 None 28.63985012578248 due to complete lack of good data\n",
      "outlier 1013 None 28.42876104604594 due to complete lack of good data\n",
      "outlier 1014 None 1.315924840318032 due to future boxes lacking data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomoly detected 1169 87.25 [594, 439, 662, 501]\n",
      "anomoly detected 1189 None [590, 439, 660, 503]\n",
      "anomoly detected 1251 152 [588, 438, 659, 502]\n",
      "anomoly detected 1923 None [581, 435, 669, 515]\n",
      "anomoly detected 1924 None [581, 435, 669, 515]\n",
      "outlier 42 5.587053685776047 5.2827956959925295 due to complete lack of good data\n",
      "outlier 45 5.416741485536182 0.25 due to complete lack of good data\n",
      "outlier 46 5.0962151943920775 0.0 due to complete lack of good data\n",
      "outlier 51 0.0 5.364381276368433 due to complete lack of good data\n",
      "outlier 56 None 5.28919784941919 due to complete lack of good data\n",
      "outlier 57 None 5.717583095306143 due to complete lack of good data\n",
      "outlier 58 None 6.125 due to complete lack of good data\n",
      "outlier 59 None 0.0 due to complete lack of good data\n",
      "outlier 60 None None due to complete lack of good data\n",
      "outlier 195 8.013876853447538 0.0 due to complete lack of good data\n",
      "outlier 196 8.5 None due to complete lack of good data\n",
      "outlier 241 5.974830277570721 5.99207016715734 due to complete lack of good data\n",
      "outlier 317 5.429790487140406 None due to complete lack of good data\n",
      "outlier 363 6.064849379183399 0.0 due to complete lack of good data\n",
      "outlier 364 6.384027500120214 None due to complete lack of good data\n",
      "outlier 381 None 0.0 due to complete lack of good data\n",
      "outlier 382 None None due to complete lack of good data\n",
      "outlier 395 None 0.0 due to complete lack of good data\n",
      "outlier 396 None None due to complete lack of good data\n",
      "outlier 832 None None due to complete lack of good data\n",
      "outlier 913 None None due to complete lack of good data\n",
      "outlier 43 5.623040931470699 0.0 due to complete lack of good data\n",
      "outlier 44 5.183373915843506 None due to complete lack of good data\n",
      "5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1929it [25:24,  1.26it/s]\n",
      "1930it [25:25,  1.24it/s]\n",
      "1931it [25:26,  1.20it/s]\n",
      "1932it [25:26,  1.19it/s]\n",
      "1933it [25:27,  1.18it/s]\n",
      "1934it [25:28,  1.20it/s]\n",
      "1935it [25:29,  1.20it/s]\n",
      "1936it [25:30,  1.20it/s]\n",
      "1937it [25:31,  1.23it/s]\n",
      "1938it [25:31,  1.23it/s]\n",
      "1939it [25:32,  1.21it/s]\n",
      "1940it [25:33,  1.22it/s]\n",
      "1941it [25:34,  1.18it/s]\n",
      "1942it [25:35,  1.13it/s]\n",
      "1943it [25:36,  1.12it/s]\n",
      "1943it [25:37,  1.26it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/demo.py\", line 329, in <module>\n",
      "    detect(cfg,opt)\n",
      "  File \"tools/demo.py\", line 297, in detect\n",
      "    with open(new_csv_path, \"w\", newline='') as new_csv:\n",
      "PermissionError: [Errno 13] Permission denied: '../csv_raw_output\\\\20200306_123926_EF.mp4.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import statistics as stats\n",
    "import cv2\n",
    "\n",
    "for detection_csv in os.listdir(csv_dir):\n",
    "  detection_csv_path = os.path.join(csv_dir, detection_csv)\n",
    "  \n",
    "  video_name = detection_csv.split(\".csv\")[0]\n",
    "\n",
    "  if video_name in os.listdir(source_dir):\n",
    "    source_video_path = os.path.join(source_dir, video_name)\n",
    "    video_reader = cv2.VideoCapture(source_video_path)\n",
    "    video_res = [int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))]\n",
    "    video_reader.release()\n",
    "    print(\"using source video\")\n",
    "  else:\n",
    "    continue\n",
    "\n",
    "\n",
    "  # adds detections grouped by frame\n",
    "  # dictionary {frame_number: [detections]}\n",
    "  detections_by_frame = {}\n",
    "  print(video_name)\n",
    "  with open(detection_csv_path, \"r\") as detection_csv_file:\n",
    "    csv_reader = csv.reader(detection_csv_file)\n",
    "    for row in list(csv_reader):\n",
    "      frame_number = int(float(row[0]))\n",
    "      detections_by_frame[frame_number] = row[1:]\n",
    "\n",
    "  # FIRST PASS\n",
    "  # decides lane 0 cars\n",
    "  for frame in sorted(detections_by_frame.keys()):\n",
    "    # defines lane 0 through area and distance from center\n",
    "    minimum_diff = None\n",
    "    for detection in detections_by_frame[frame]:\n",
    "      if float(detection.split(\" \")[5]) < confidence_threshold: # will skip detections below confidence threshold\n",
    "        continue\n",
    "      lane_number, x1, y1, x2, y2, conf, frame_center = read_csv_detection(detection)[:7]\n",
    "      if lane_number == 0: # chooses lane zero through weighted parameters\n",
    "        midpoint = int(stats.mean([x1, x2]))\n",
    "        diff = abs(frame_center - midpoint)\n",
    "        bound_box_area = (x2 - x1) * (y2 - y1)\n",
    "        img_area = video_res[0] * video_res[1]\n",
    "        area_weight = 1 - ((bound_box_area / img_area) ** 0.2)\n",
    "        diff_weight = (diff / video_res[0]) ** 2 + 0.075\n",
    "        weight = diff_weight * area_weight\n",
    "        if minimum_diff is None or weight < minimum_diff[1]:\n",
    "          minimum_diff = [[x1,y1,x2,y2], weight]\n",
    "\n",
    "    # removes all other lane 0 except for one car\n",
    "    for i in range(len(detections_by_frame[frame])):\n",
    "      detection = detections_by_frame[frame][i]\n",
    "\n",
    "      lane_number, x1, y1, x2, y2, conf, frame_center = read_csv_detection(detection)[:7]\n",
    "\n",
    "      if(len(detection.split(\" \")) >= 8):\n",
    "        class_id = read_csv_detection(detection)[7]\n",
    "\n",
    "      if lane_number == 0: # remove all other lane 0\n",
    "        if not minimum_diff is None:\n",
    "          if [x1,y1,x2,y2] != minimum_diff[0]:\n",
    "            midpoint = int(stats.mean([x1, x2]))\n",
    "            new_lane_number = 0\n",
    "            if midpoint > frame_center:\n",
    "              new_lane_number = 1\n",
    "            else:\n",
    "              new_lane_number = -1\n",
    "            # adjust lane number of false lane 0\n",
    "            detections_by_frame[frame][i] = f\"{new_lane_number} {x1} {y1} {x2} {y2} {conf} {frame_center}\"\n",
    "            if(len(detection.split(\" \")) >= 8):\n",
    "              detections_by_frame[frame][i] += f\" {class_id}\"\n",
    "            # end adjusting\n",
    "  # END FIRST PASS\n",
    "\n",
    "\n",
    "  # SECOND PASS\n",
    "  # stabilizes lane 0 cars from the past\n",
    "  previous_frame_count = 5\n",
    "  for frame_index in range(len(detections_by_frame.keys())):\n",
    "    if frame_index != 0 and frame_index != len(detections_by_frame) - 1:\n",
    "\n",
    "      # gathers all the lane 0 bounding boxes from the past 5 frames\n",
    "      prev_centers = []\n",
    "      for i in range(previous_frame_count):\n",
    "        if frame_index - i < 0:\n",
    "          continue\n",
    "        detection_data = find_lane_zero(detections_by_frame[list(detections_by_frame.keys())[frame_index - 1]])\n",
    "        if not detection_data is None:\n",
    "          lane_number, x1, y1, x2, y2, conf, frame_center = detection_data[:7]\n",
    "\n",
    "          center_previous = (stats.mean([x1, x2]), stats.mean([y1, y2]))\n",
    "          prev_centers.append(center_previous)\n",
    "        else:\n",
    "          continue\n",
    "      # end gathering\n",
    "\n",
    "      #finds the minimum difference between current lane 0 and past 5 lane 0 cars\n",
    "      #sets the default minimum difference to compare to (current lane 0)\n",
    "      minimum_diff = []\n",
    "      detection_data = find_lane_zero(detections_by_frame[list(detections_by_frame.keys())[frame_index]])\n",
    "      if not detection_data is None:\n",
    "        lane_number, x1, y1, x2, y2, conf, frame_center = detection_data[:7]\n",
    "\n",
    "        prev_diffs = []\n",
    "        center_zero = (stats.mean([x1, x2]), stats.mean([y1, y2]))\n",
    "        for center_previous in prev_centers:\n",
    "          prev_diff = abs(center_zero[0] - center_previous[0]) + abs(center_zero[1] - center_previous[1])\n",
    "          prev_diffs.append(prev_diff)\n",
    "        if len(prev_diffs) == 0:\n",
    "          continue\n",
    "\n",
    "        original = [(x1,y1,x2,y2), stats.mean(prev_diffs)]\n",
    "        minimum_diff = [(x1,y1,x2,y2), stats.mean(prev_diffs)]\n",
    "\n",
    "      else:\n",
    "        continue\n",
    "      # end finding min difference of lane 0\n",
    "\n",
    "      #finds minimum difference between all bounding boxes and past 5 lane 0 cars\n",
    "      for i in range(len(detections_by_frame[list(detections_by_frame.keys())[frame_index]])):\n",
    "        detection = detections_by_frame[list(detections_by_frame.keys())[frame_index]][i]\n",
    "        detection_data = read_csv_detection(detection)\n",
    "\n",
    "        lane_number, x1, y1, x2, y2, conf, frame_center = detection_data[:7]\n",
    "\n",
    "        if len(detection_data) <= 7:\n",
    "          continue\n",
    "\n",
    "        # list of differences between current box and past boxes\n",
    "        prev_diffs = []\n",
    "        center_curr = (stats.mean([x1, x2]), stats.mean([y1, y2]))\n",
    "        for prev_center in prev_centers:\n",
    "          prev_diff = abs(center_curr[0] - prev_center[0]) + abs(center_curr[1] - prev_center[1])\n",
    "          prev_diffs.append(prev_diff)\n",
    "        if len(prev_diffs) == 0:\n",
    "          continue\n",
    "        \n",
    "        if stats.mean(prev_diffs) < minimum_diff[1]:\n",
    "          minimum_diff = [(x1,y1,x2,y2), stats.mean(prev_diffs), i]\n",
    "      # end finding min difference of all bounding boxes\n",
    "\n",
    "\n",
    "      # assigns new lane 0 car with minimum difference, and gives lane number to old lane 0 car\n",
    "      if minimum_diff[0] != original[0] and abs(minimum_diff[1] - original[1]) > 0:\n",
    "        if len(minimum_diff) > 2:\n",
    "          # removes old lane 0 car\n",
    "          new_zero_detection = detections_by_frame[list(detections_by_frame.keys())[frame_index]][minimum_diff[2]]\n",
    "          old_zero = find_lane_zero(detections_by_frame[list(detections_by_frame.keys())[frame_index]])\n",
    "\n",
    "          for i in range(len(detections_by_frame[list(detections_by_frame.keys())[frame_index]])):\n",
    "            if detections_by_frame[list(detections_by_frame.keys())[frame_index]][i] == old_zero:\n",
    "              lane_number, x1, y1, x2, y2, conf, frame_center = old_zero\n",
    "              if (len(old_zero) >= 8):\n",
    "                class_id = old_zero[7]\n",
    "\n",
    "            # adjust lane number of false lane 0\n",
    "            new_lane_number = 0\n",
    "            if stats.mean([x1,x2]) > frame_center:\n",
    "              new_lane_number = 1\n",
    "            else:\n",
    "              new_lane_number = -1\n",
    "            write_detection = f\"{new_lane_number} {x1} {y1} {x2} {y2} {conf} {frame_center}\"\n",
    "            \n",
    "            if enforce_external_boxes:\n",
    "              write_detection += f\" {class_id}\"\n",
    "            detections_by_frame[list(detections_by_frame.keys())[frame_index]][i] = write_detection\n",
    "            # end adjustment\n",
    "\n",
    "          # write the new lane 0 car\n",
    "          detection_data = read_csv_detection(new_zero_detection)\n",
    "          lane_number, x1, y1, x2, y2, conf, frame_center = detection_data[:7]\n",
    "\n",
    "          write_detection = f\"0 {x1} {y1} {x2} {y2} {conf} {frame_center}\"\n",
    "          if(len(detection_data) >= 8):\n",
    "            write_detection += f\" {detection_data[7]}\"\n",
    "          # end writing new lane 0 car\n",
    "            \n",
    "          detections_by_frame[list(detections_by_frame.keys())[frame_index]][minimum_diff[2]] = write_detection\n",
    "      # end assignment\n",
    "  # END SECOND PASS\n",
    "\n",
    "\n",
    "\n",
    "  # THIRD PASS \n",
    "  # detects anomoly\n",
    "  # this pass repeats to adjust all anomolies (gaps or jumps)\n",
    "  max_range = 7\n",
    "  minimum_list_size = 3\n",
    "  max_st_dev = 5\n",
    "  mean_difference_threshold = 75\n",
    "  max_passes = 5\n",
    "  pass_number = 0\n",
    "\n",
    "  anomoly_detected = True\n",
    "  while pass_number < max_passes and anomoly_detected is True:\n",
    "    anomoly_detected = False\n",
    "    for frame_index in range(len(detections_by_frame.keys())):\n",
    "      \n",
    "      # determine if there is a gap or jump\n",
    "      current_detection = find_lane_zero(detections_by_frame[list(detections_by_frame.keys())[frame_index]])\n",
    "\n",
    "      # gather lane 0 bounding boxes before current detection\n",
    "      past_boxes = []\n",
    "      for i in range(max_range):\n",
    "        if frame_index - 1 - i >= 0:\n",
    "          past_box = find_lane_zero(detections_by_frame[list(detections_by_frame.keys())[frame_index - 1 - i]])\n",
    "          if not past_box is None:\n",
    "            past_boxes.append(past_box[1:5])\n",
    "            if(len(past_box) >= 8):\n",
    "              predicted_class_id = past_box[7]\n",
    "            \n",
    "      # gather lane 0 bounding boxes after current detection\n",
    "      future_boxes = []\n",
    "      for i in range(max_range):\n",
    "        if frame_index + 1 + i < len(detections_by_frame.keys()):\n",
    "          future_box = find_lane_zero(detections_by_frame[list(detections_by_frame.keys())[frame_index + 1 + i]])\n",
    "          if not future_box is None:\n",
    "            future_boxes.append(future_box[1:5])\n",
    "\n",
    "      # remove outliers\n",
    "      # outliers are detections with lack of good detections near it\n",
    "      past_coord_mean, past_st_dev = None, None\n",
    "      if len(past_boxes) != 0:\n",
    "        past_coord_mean, past_st_dev = get_boxes_stats(past_boxes)\n",
    "\n",
    "      future_coord_mean, future_st_dev = None, None\n",
    "      if len(future_boxes) != 0:\n",
    "        future_coord_mean, future_st_dev = get_boxes_stats(future_boxes)\n",
    "      \n",
    "      past_detections_good = True\n",
    "      if len(past_boxes) < minimum_list_size or past_st_dev > max_st_dev:\n",
    "        past_detections_good = False\n",
    "\n",
    "      future_detections_good = True\n",
    "      if len(future_boxes) < minimum_list_size or future_st_dev > max_st_dev:\n",
    "        future_detections_good = False\n",
    "\n",
    "      # missing 1 side or both sides\n",
    "      if not past_detections_good or not future_detections_good:\n",
    "        if not current_detection is None:\n",
    "          remove_lane_zero = False\n",
    "\n",
    "          # complete lack of data\n",
    "          if not past_detections_good and not future_detections_good:\n",
    "            removal_reason = \"due to complete lack of good data\"\n",
    "            remove_lane_zero = True\n",
    "          \n",
    "          # 1 sided data that doesn't match\n",
    "          else:\n",
    "            if len(past_boxes) >= minimum_list_size:\n",
    "              other_coord_mean = past_coord_mean\n",
    "              removal_reason = \"due to past boxes lacking data\"\n",
    "            else:\n",
    "              other_coord_mean = future_coord_mean\n",
    "              removal_reason = \"due to future boxes lacking data\"\n",
    "            current_coords = current_detection[1:5]\n",
    "            # check mean difference from current coord to one side (past or present)\n",
    "            if stats.mean([abs(current_coords[i] - other_coord_mean[i]) for i in range(len(current_coords))]) > mean_difference_threshold:\n",
    "              remove_lane_zero = True\n",
    "\n",
    "          # remove lane 0 detection\n",
    "          if remove_lane_zero:\n",
    "            anomoly_detected = True\n",
    "            print(\"outlier\", list(detections_by_frame.keys())[frame_index], past_st_dev, future_st_dev, removal_reason)\n",
    "            for i in range(len(detections_by_frame[list(detections_by_frame.keys())[frame_index]])):\n",
    "              detection = read_csv_detection(detections_by_frame[list(detections_by_frame.keys())[frame_index]][i])\n",
    "\n",
    "              lane_number, x1, y1, x2, y2, conf, frame_center = detection[:7]\n",
    "\n",
    "              new_lane_number = 0\n",
    "              if stats.mean([x1,x2]) > frame_center:\n",
    "                new_lane_number = 1\n",
    "              else:\n",
    "                new_lane_number = -1\n",
    "              write_detection = f\"{new_lane_number} {x1} {y1} {x2} {y2} {conf} {frame_center}\"\n",
    "              if len(detection) >= 8:\n",
    "                write_detection += f\" {detection[7]}\"\n",
    "              detections_by_frame[list(detections_by_frame.keys())[frame_index]][i] = write_detection\n",
    "        continue\n",
    "      \n",
    "      average_difference = None\n",
    "\n",
    "      predicted_current_coords = get_boxes_stats([past_coord_mean, future_coord_mean])[0]\n",
    "\n",
    "\n",
    "\n",
    "      # get average differences\n",
    "      if not current_detection is None:\n",
    "        current_coords = current_detection[1:5]\n",
    "        average_difference = stats.mean([abs(current_coords[i] - predicted_current_coords[i]) for i in range(len(current_coords))])\n",
    "\n",
    "      # either gap or jump here\n",
    "      if current_detection is None or average_difference > mean_difference_threshold:\n",
    "        anomoly_detected = True\n",
    "        print(\"anomoly detected\", list(detections_by_frame.keys())[frame_index], average_difference, predicted_current_coords)\n",
    "        \n",
    "        # removes old detection\n",
    "        if not current_detection is None:\n",
    "          for i in range(len(detections_by_frame[list(detections_by_frame.keys())[frame_index]])):\n",
    "            detection = read_csv_detection(detections_by_frame[list(detections_by_frame.keys())[frame_index]][i])\n",
    "            lane_number, x1, y1, x2, y2, conf, frame_center = detection[:7]\n",
    "                      \n",
    "            if stats.mean([x1,x2]) > frame_center:\n",
    "              new_lane_number = 1\n",
    "            else:\n",
    "              new_lane_number = -1\n",
    "\n",
    "            # adjusts lane number of false lane 0\n",
    "            write_detection  = f\"{new_lane_number} {x1} {y1} {x2} {y2} {conf} {frame_center}\"\n",
    "            if len(detection) >= 8:\n",
    "              write_detection += f\" {detection[7]}\"\n",
    "            detections_by_frame[list(detections_by_frame.keys())[frame_index]][i] = write_detection\n",
    "            # end adjust\n",
    "\n",
    "        # create lane 0 prediction from averages\n",
    "        x1, y1, x2, y2 = predicted_current_coords\n",
    "        conf = 1\n",
    "        frame_center = int(float(detections_by_frame[list(detections_by_frame.keys())[frame_index]][0].split(\" \")[6]))\n",
    "\n",
    "        # write lane 0 detection to fill gap\n",
    "        write_detection = f\"0 {x1} {y1} {x2} {y2} {conf} {frame_center}\"\n",
    "        if enforce_external_boxes:\n",
    "          write_detection += f\" {predicted_class_id}\"\n",
    "        detections_by_frame[list(detections_by_frame.keys())[frame_index]].append(write_detection)\n",
    "        # end write lane 0 detection\n",
    "\n",
    "    pass_number += 1\n",
    "  # END THIRD PASS\n",
    "      \n",
    "  # creates directory\n",
    "  if not (os.path.exists(processed_csv_dir) and os.path.isdir(processed_csv_dir)):\n",
    "    os.mkdir(processed_csv_dir)\n",
    "  processed_csv_path = os.path.join(processed_csv_dir, detection_csv)\n",
    "\n",
    "  # writes to csv\n",
    "  with open(processed_csv_path, \"w\", newline='') as detection_csv_file:\n",
    "    csv_writer = csv.writer(detection_csv_file)\n",
    "    for frame in sorted(detections_by_frame.keys()):\n",
    "      detection_length = 0\n",
    "      if enforce_external_boxes:\n",
    "        detection_length = 8\n",
    "      else:\n",
    "        detection_length = 7\n",
    "      csv_writer.writerow([frame] + [\" \".join(x.split(\" \")[:detection_length]) for x in detections_by_frame[frame]])\n",
    "\n",
    "\n",
    "  # below handles writing to lane zeros\n",
    "  detection_csv_path = os.path.join(csv_dir, detection_csv)\n",
    "  video_name = detection_csv.split(\".csv\")[0]\n",
    "\n",
    "  video_frames = video_res[2]\n",
    "  print(video_frames)\n",
    "\n",
    "  # create header and empty csv file\n",
    "  lane_zeros = []\n",
    "  lane_zeros.append([\"Frame number\", \"x1\", \"y1\", \"x2\", \"y2\", \"confidence\", \"Lane center\", \"Class\"])\n",
    "  for i in range(video_frames + 1):\n",
    "    lane_zeros.append([i + 1, \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\", \"NA\"])\n",
    "\n",
    "  # gather lane zeros\n",
    "  for frame in sorted(detections_by_frame.keys()):\n",
    "    lane_zero = find_lane_zero(detections_by_frame[frame])\n",
    "    if not lane_zero is None:\n",
    "      lane_number, x1, y1, x2, y2, conf, frame_center = lane_zero[0:7]\n",
    "\n",
    "      lane_zeros[frame] = [frame, x1, y1, x2, y2, conf, frame_center]\n",
    "      if len(lane_zero) >= 8:\n",
    "        lane_zeros[frame].append(lane_zero[7]) # class_id\n",
    "      #print(frame)\n",
    "        \n",
    "  # create folder\n",
    "  if not (os.path.exists(zeros_dir) and os.path.isdir(zeros_dir)):\n",
    "    os.mkdir(zeros_dir)\n",
    "\n",
    "  # write to csv file\n",
    "  zeros_csv_dir = os.path.join(zeros_dir, detection_csv)\n",
    "  with open(zeros_csv_dir, 'w', newline='') as zeros_csv:\n",
    "    csv_writer = csv.writer(zeros_csv)\n",
    "    csv_writer.writerows(lane_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXvs4K_EEudJ"
   },
   "source": [
    "## Closest boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJuCS_LBEtmh"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "\n",
    "# create folder\n",
    "if not (os.path.exists(closest_dir) and os.path.isdir(closest_dir)):\n",
    "  os.mkdir(closest_dir)\n",
    "\n",
    "for detection_csv in os.listdir(processed_csv_dir):\n",
    "  detection_csv_path = os.path.join(processed_csv_dir, detection_csv)\n",
    "  csv_array = []\n",
    "\n",
    "  with open(detection_csv_path, \"r\") as detection_csv_file:\n",
    "    csv_reader = csv.reader(detection_csv_file)\n",
    "    csv_array = list(csv_reader)\n",
    "\n",
    "  closest_array = []\n",
    "  for detections in csv_array:\n",
    "    frame_number = detections[0]\n",
    "    left_car = find_largest_box(detections[1:], -1)\n",
    "    zero_car = find_largest_box(detections[1:], 0)\n",
    "    right_car = find_largest_box(detections[1:], 1)\n",
    "    closest_array.append([frame_number, left_car, zero_car, right_car])\n",
    "\n",
    "\n",
    "  # write to csv file\n",
    "  closest_csv_dir = os.path.join(closest_dir, detection_csv)\n",
    "  with open(closest_csv_dir, 'w', newline='') as closest_csv:\n",
    "    csv_writer = csv.writer(closest_csv)\n",
    "    csv_writer.writerows(closest_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "te0xVC3umRc_"
   },
   "source": [
    "## Generate video with bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "313bzKqCmTk8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "# either processed_csv_dir, or closest_dir\n",
    "target_dir = closest_dir\n",
    "\n",
    "print(os.listdir(csv_dir))\n",
    "print(os.listdir(source_dir))\n",
    "print(os.listdir(save_dir))\n",
    "\n",
    "tl = 2\n",
    "tf = max(tl - 1, 1)\n",
    "\n",
    "for detection_csv in os.listdir(csv_dir):\n",
    "\n",
    "  randomf = random.random()\n",
    "  if randomf > 0.4:\n",
    "    continue\n",
    "\n",
    "\n",
    "\n",
    "  write_video_res = (1280, 720)\n",
    "  detection_csv_path = os.path.join(target_dir, detection_csv)\n",
    "  \n",
    "  video_name = detection_csv.split(\".csv\")[0]\n",
    "\n",
    "  source_video_path = os.path.join(source_dir, video_name)\n",
    "\n",
    "  video_reader = cv2.VideoCapture(source_video_path)\n",
    "  video_res = [int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))]\n",
    "  #video_reader.release()\n",
    "\n",
    "\n",
    "  detections_by_frame = {}\n",
    "  csv_array = []\n",
    "\n",
    "  \n",
    "\n",
    "  with open(detection_csv_path, \"r\") as detection_csv_file:\n",
    "    csv_reader = csv.reader(detection_csv_file)\n",
    "    csv_array = list(csv_reader)\n",
    "  \n",
    "  video_output_path = os.path.join(save_dir, detection_csv.split(\".csv\")[0])\n",
    "\n",
    "  fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "  video_writer = cv2.VideoWriter(video_output_path, fourcc, int(detection_fps), (write_video_res[0], write_video_res[1]))\n",
    "  \n",
    "  lane_number = None\n",
    "  past_row = None\n",
    "\n",
    "  for i in range(math.ceil(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "\n",
    "    if len(csv_array) > 0 and len(csv_array[0]) > 1 and int(float(csv_array[0][0])) == i:\n",
    "      #print(\"passes\")\n",
    "      row = csv_array.pop(0)\n",
    "      frame_number = int(float(row[0]))\n",
    "    else:\n",
    "      row = []\n",
    "      frame_number = -1\n",
    "\n",
    "    if detection_fps != int(math.ceil(video_reader.get(cv2.CAP_PROP_FPS))):\n",
    "      print(\"not\")\n",
    "      video_reader.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "\n",
    "    success, frame = video_reader.read()\n",
    "    if success:\n",
    "      #print(frame_number)\n",
    "      \n",
    "      frame = cv2.resize(frame, write_video_res)\n",
    "      if len(row) > 1:\n",
    "        for detection in row[1:]:\n",
    "          if detection is None or len(detection) <= 0:\n",
    "            continue\n",
    "\n",
    "          past_row = row\n",
    "          print(detection)\n",
    "          detection_data = read_csv_detection(detection)\n",
    "          lane_number = None\n",
    "          lane_number, x1, y1, x2, y2, conf, frame_center = detection_data[0:7]\n",
    "          class_id = None\n",
    "          if len(detection_data) > 7:\n",
    "            class_id = detection_data[7]\n",
    "          c1, c2 = (x1, y1), (x2, y2)\n",
    "          if not lane_number is None:\n",
    "            if lane_number == 0:\n",
    "              color = [0, 255, 0]\n",
    "            else:\n",
    "              color = [0, 0, 255]\n",
    "            cv2.rectangle(frame, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "                    \n",
    "            label = str(lane_number)\n",
    "            if(class_id == 3):\n",
    "              label += \" car\"\n",
    "            elif(class_id == 4):\n",
    "              label += \" motorcycle\"\n",
    "            elif(class_id == 6):\n",
    "              label += \" bus\"\n",
    "            elif(class_id == 8):\n",
    "              label += \" truck\"\n",
    "            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "            c2 = c1[0] + t_size[0], c1[1] - t_size[1]\n",
    "            cv2.rectangle(frame, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "            cv2.putText(frame, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "      elif past_row and False == True:\n",
    "        for detection in past_row[1:]:\n",
    "          detection_data = read_csv_detection(detection)\n",
    "          lane_number = None\n",
    "          lane_number, x1, y1, x2, y2, conf, frame_center = detection_data[0:7]\n",
    "          c1, c2 = (x1, y1), (x2, y2)\n",
    "          if not lane_number is None:\n",
    "            if lane_number == 0:\n",
    "              color = [0, 255, 0]\n",
    "            else:\n",
    "              color = [0, 0, 255]\n",
    "            cv2.rectangle(frame, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "      label2 = str(i)\n",
    "      t_size2 = cv2.getTextSize(label2, 0, fontScale=2 / 3, thickness=1)[0]\n",
    "      cv2.rectangle(frame, (0,0), (t_size2[0], t_size2[1]), (0,0,0), -1, cv2.LINE_AA)\n",
    "      cv2.putText(frame, label2, (0, t_size2[1] + 3), 0, 2 / 3, [225, 255, 255], thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "      video_writer.write(frame)\n",
    "  video_writer.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbVmrj4V6ZJC"
   },
   "source": [
    "## Test center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpdBSrRB6Djz"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "test_center = 615\n",
    "center_distance = 50\n",
    "frame_number = 3000\n",
    "\n",
    "video_reader = cv2.VideoCapture(os.path.join(source_dir, os.listdir(source_dir)[13]))\n",
    "video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "video_res = [int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))]\n",
    "print(video_res)\n",
    "\n",
    "print(os.path.join(source_dir, os.listdir(source_dir)[4]))\n",
    "\n",
    "success, frame = video_reader.read()\n",
    "if success: \n",
    "  cv2.line(frame, (int(test_center * video_res[0] / 1280), int(video_res[1] * 1 / 3)), (int(test_center * video_res[0] / 1280), int(video_res[1] * 2 / 3)), (255,0,0), 3)\n",
    "  cv2.line(frame, (int(test_center * video_res[0] / 1280) + center_distance, int(video_res[1] * 1 / 3)), (int(test_center * video_res[0] / 1280) + center_distance, int(video_res[1] * 2 / 3)), (0, 255,0), 3)\n",
    "  cv2.line(frame, (int(test_center * video_res[0] / 1280) - center_distance, int(video_res[1] * 1 / 3)), (int(test_center * video_res[0] / 1280) - center_distance, int(video_res[1] * 2 / 3)), (0, 255,0), 3)\n",
    "  #cv2.imwrite(\"../test.png\", frame)\n",
    "  cv2_imshow(frame)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "mwPy3ylhfWA7",
    "FTGwfo7LFSZU",
    "N__bR5n_742n",
    "3pz7eny7ZGck",
    "te0xVC3umRc_"
   ],
   "name": "Lane Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
